{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     /Users/robbieardison/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tagged Text (using random sentence from Brown):\n",
      "[('The', 'DT'), ('Fulton', 'NNP'), ('County', 'NNP'), ('Grand', 'NNP'), ('Jury', 'NNP'), ('said', 'VBD'), ('Friday', 'NNP'), ('an', 'DT'), ('investigation', 'NN'), ('of', 'IN'), ('Atlanta', 'NNP'), (\"'s\", 'POS'), ('recent', 'JJ'), ('primary', 'JJ'), ('election', 'NN'), ('produced', 'VBD'), ('``', '``'), ('no', 'DT'), ('evidence', 'NN'), ('``', '``'), ('that', 'IN'), ('any', 'DT'), ('irregularities', 'NNS'), ('took', 'VBD'), ('place', 'NN'), ('.', '.')]\n",
      "\n",
      "Tagged My Text:\n",
      "[('The', 'DT'), ('quick', 'JJ'), ('brown', 'NN'), ('fox', 'NN'), ('jumps', 'VBZ'), ('over', 'IN'), ('the', 'DT'), ('lazy', 'JJ'), ('dog', 'NN'), ('.', '.')]\n",
      "\n",
      "Tagged 'ca01' section:\n",
      "[('The', 'DT'), ('Fulton', 'NNP'), ('County', 'NNP'), ('Grand', 'NNP'), ('Jury', 'NNP'), ('said', 'VBD'), ('Friday', 'NNP'), ('an', 'DT'), ('investigation', 'NN'), ('of', 'IN'), ('Atlanta', 'NNP'), (\"'s\", 'POS'), ('recent', 'JJ'), ('primary', 'JJ'), ('election', 'NN'), ('produced', 'VBD'), ('``', '``'), ('no', 'DT'), ('evidence', 'NN'), ('``', '``'), ('that', 'IN'), ('any', 'DT'), ('irregularities', 'NNS'), ('took', 'VBD'), ('place', 'NN'), ('.', '.'), ('The', 'DT'), ('jury', 'NN'), ('further', 'RB'), ('said', 'VBD'), ('in', 'IN'), ('term-end', 'JJ'), ('presentments', 'NNS'), ('that', 'IN'), ('the', 'DT'), ('City', 'NNP'), ('Executive', 'NNP'), ('Committee', 'NNP'), (',', ','), ('which', 'WDT'), ('had', 'VBD'), ('over-all', 'JJ'), ('charge', 'NN'), ('of', 'IN'), ('the', 'DT'), ('election', 'NN'), (',', ','), ('``', '``'), ('deserves', 'VBZ'), ('the', 'DT'), ('praise', 'NN'), ('and', 'CC'), ('thanks', 'NNS'), ('of', 'IN'), ('the', 'DT'), ('City', 'NNP'), ('of', 'IN'), ('Atlanta', 'NNP'), ('``', '``'), ('for', 'IN'), ('the', 'DT'), ('manner', 'NN'), ('in', 'IN'), ('which', 'WDT'), ('the', 'DT'), ('election', 'NN'), ('was', 'VBD'), ('conducted', 'VBN'), ('.', '.'), ('The', 'DT'), ('September-October', 'NNP'), ('term', 'NN'), ('jury', 'NN'), ('had', 'VBD'), ('been', 'VBN'), ('charged', 'VBN'), ('by', 'IN'), ('Fulton', 'NNP'), ('Superior', 'NNP'), ('Court', 'NNP'), ('Judge', 'NNP'), ('Durwood', 'NNP'), ('Pye', 'NNP'), ('to', 'TO'), ('investigate', 'VB'), ('reports', 'NNS'), ('of', 'IN'), ('possible', 'JJ'), ('``', '``'), ('irregularities', 'NNS'), ('``', '``'), ('in', 'IN'), ('the', 'DT'), ('hard-fought', 'JJ'), ('primary', 'NN'), ('which', 'WDT'), ('was', 'VBD'), ('won', 'VBN'), ('by', 'IN'), ('Mayor-nominate', 'NNP'), ('Ivan', 'NNP')]\n",
      "Word: The, Tag: DT\n",
      "Word: quick, Tag: JJ\n",
      "Word: brown, Tag: NN\n",
      "Word: fox, Tag: NN\n",
      "Word: jumps, Tag: VBZ\n",
      "Word: over, Tag: IN\n",
      "Word: the, Tag: DT\n",
      "Word: lazy, Tag: JJ\n",
      "Word: dog, Tag: NN\n",
      "Word: ., Tag: .\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import brown\n",
    "\n",
    "try:\n",
    "    nltk.data.find('corpora/brown')\n",
    "except LookupError:\n",
    "    nltk.download('brown')\n",
    "\n",
    "try:\n",
    "    nltk.data.find('taggers/averaged_perceptron_tagger_eng')\n",
    "except LookupError:\n",
    "    nltk.download('averaged_perceptron_tagger_eng')\n",
    "\n",
    "\n",
    "\n",
    "def pos_tag_brown(text=None):\n",
    "    \"\"\"\n",
    "    Performs Part-of-Speech (POS) tagging on text from the Brown Corpus.\n",
    "\n",
    "    Args:\n",
    "        text (str, optional): The input text. If None, uses a random sentence from Brown.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of (word, tag) tuples.\n",
    "        or None if there is an issue or the text is empty\n",
    "    \"\"\"\n",
    "\n",
    "    if text is None:\n",
    "        # Get a random sentence from the Brown Corpus\n",
    "        sentences = brown.sents()\n",
    "        if not sentences:  # Check if sentences is empty\n",
    "            print(\"Brown corpus is empty or not loaded correctly.\")\n",
    "            return None\n",
    "        \n",
    "        text = \" \".join(sentences[0]) # Join the first sentence for demonstration.  You can change this.\n",
    "\n",
    "\n",
    "    if not text:  # Check if text is empty\n",
    "        print(\"Input text is empty.\")\n",
    "        return None\n",
    "\n",
    "    tokens = nltk.word_tokenize(text)  # Tokenize the text\n",
    "    tagged_tokens = nltk.pos_tag(tokens)  # Perform POS tagging\n",
    "\n",
    "    return tagged_tokens\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "tagged_text = pos_tag_brown()  # Using a random sentence from Brown\n",
    "if tagged_text:\n",
    "    print(\"Tagged Text (using random sentence from Brown):\")\n",
    "    print(tagged_text)\n",
    "\n",
    "# Or use your own text:\n",
    "my_text = \"The quick brown fox jumps over the lazy dog.\"\n",
    "tagged_my_text = pos_tag_brown(my_text)\n",
    "if tagged_my_text:\n",
    "    print(\"\\nTagged My Text:\")\n",
    "    print(tagged_my_text)\n",
    "\n",
    "\n",
    "# Demonstrating using a specific section of the brown corpus.\n",
    "# You can specify which fileids to use.  See brown.fileids() for the options.\n",
    "# Here's an example of using the 'ca01' fileid.\n",
    "\n",
    "ca01_words = brown.words(fileids=['ca01'])\n",
    "ca01_text = \" \".join(ca01_words[:100]) # using first 100 words. Adjust as needed.\n",
    "tagged_ca01 = pos_tag_brown(ca01_text)\n",
    "if tagged_ca01:\n",
    "    print(\"\\nTagged 'ca01' section:\")\n",
    "    print(tagged_ca01)\n",
    "\n",
    "\n",
    "# Example of iterating through the tagged words and tags:\n",
    "if tagged_my_text:\n",
    "    for word, tag in tagged_my_text:\n",
    "        print(f\"Word: {word}, Tag: {tag}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-pro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
